{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGIONS = [\n",
    "    'Greater Montreal',\n",
    "    'Greater Toronto Area',\n",
    "    'Metro Vancouver'\n",
    "]\n",
    "\n",
    "CSDs = [\n",
    "    'Halifax',\n",
    "    'Quebec City',\n",
    "    'Island of Montreal',\n",
    "    'Ottawa',\n",
    "    'Toronto',\n",
    "    'Winnipeg',\n",
    "    'Calgary',\n",
    "    'Edmonton',\n",
    "    'Vancouver'\n",
    "]\n",
    "\n",
    "PARTY_TAGS_MAP = {\n",
    "    'Liberal Party of Canada': 'lib',\n",
    "    'Conservative Party of Canada': 'con',\n",
    "    'New Democratic Party': 'ndp',\n",
    "    'Bloc Québécois': 'bloc',\n",
    "    'Green Party of Canada': 'grn',\n",
    "    \"People's Party of Canada\": 'ppc',\n",
    "    'Other': 'oth',\n",
    "}\n",
    "\n",
    "JSON_TAGS_MAP = {\n",
    "    'LIB': 'Liberal Party of Canada',\n",
    "    'CON': 'Conservative Party of Canada',\n",
    "    'NDP': 'New Democratic Party',\n",
    "    'BQ': 'Bloc Québécois',\n",
    "    'GRN': 'Green Party of Canada', \n",
    "    'PPC': \"People's Party of Canada\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse 2025 data and add it to results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/cbc_results.json', 'r') as file:\n",
    "    ridings = json.load(file)['data']['ridings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []  # (FED_NUM, PARTY_NAME, VOTES)\n",
    "\n",
    "for riding in ridings:\n",
    "    fed_num = float(riding['map_slug'])\n",
    "    riding_votes = 0\n",
    "    oth_votes = 0\n",
    "\n",
    "    for party in riding['parties']:\n",
    "        if party['partyCode'] in JSON_TAGS_MAP:\n",
    "            party_name = JSON_TAGS_MAP[party['partyCode']]\n",
    "            votes = party['totalVotes']\n",
    "            results.append((\n",
    "                fed_num,\n",
    "                party_name,\n",
    "                votes,\n",
    "            ))\n",
    "            riding_votes += votes\n",
    "        \n",
    "        if party['partyCode'] not in JSON_TAGS_MAP:\n",
    "            votes = party['totalVotes']\n",
    "            oth_votes += votes\n",
    "            riding_votes += votes\n",
    "    \n",
    "    results.append((\n",
    "        fed_num,\n",
    "        'Other',\n",
    "        oth_votes,\n",
    "    ))\n",
    "\n",
    "    results.append((\n",
    "        fed_num,\n",
    "        'Rejected',\n",
    "        riding_votes - riding['totalVotesReported'],\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2025 = pd.DataFrame.from_records(results, columns=['FED_NUM', 'party_name', '2025_num_votes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.read_csv('../data/fed_results.csv')\n",
    "df_results = df_results.drop(columns='2025_num_votes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.merge(df_results, df_2025, how='left', on=['FED_NUM', 'party_name'])\n",
    "df_merged['2025_num_votes'] = df_merged['2025_num_votes'].fillna(0)\n",
    "df_merged.to_csv('../data/fed_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data and clear out rejected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.read_csv('../data/fed_results.csv')\n",
    "df_ridings = pd.read_csv('../data/fed_ridings_tagged.csv')\n",
    "\n",
    "# Filter out rejected ballots\n",
    "df_results = df_results[df_results['party_name'] != 'Rejected']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the percentage of votes for each party in each CSD we target, and each region we target, as separate files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge riding metadata into results\n",
    "df = df_results.merge(df_ridings[['FED_NUM', 'CSD', 'region']], on='FED_NUM', how='left')\n",
    "\n",
    "# Define mapping for city to its metro region and the name for the suburbs-only region\n",
    "SUBURB_FILTERS = [\n",
    "    ('Greater Montreal', 'Island of Montreal', 'Greater Montreal (suburbs only)'),\n",
    "    ('Greater Toronto Area', 'Toronto', 'Greater Toronto Area (suburbs only)'),\n",
    "    ('Metro Vancouver', 'Vancouver', 'Metro Vancouver (suburbs only)'),\n",
    "]\n",
    "\n",
    "def compute_vote_shares(df, group_col, output_path):\n",
    "    \"\"\"\n",
    "    Compute percentage vote shares by group_col (CSD or region).\n",
    "    \"\"\"\n",
    "    if group_col == 'CSD':\n",
    "        df = df[df['CSD'].isin(CSDs)]\n",
    "    elif group_col == 'region':\n",
    "        df_main = df[df['region'].isin(REGIONS)].copy()\n",
    "\n",
    "        # Prepare suburban variants\n",
    "        suburb_frames = []\n",
    "        for region_name, city_name, new_region_name in SUBURB_FILTERS:\n",
    "            suburb_df = df[(df['region'] == region_name) & (df['CSD'] != city_name)].copy()\n",
    "            suburb_df['region'] = new_region_name\n",
    "            suburb_frames.append(suburb_df)\n",
    "\n",
    "        # Combine main and suburbs\n",
    "        df = pd.concat([df_main] + suburb_frames, ignore_index=True)\n",
    "    else:\n",
    "        raise ValueError(\"group_col must be 'CSD' or 'region'\")\n",
    "\n",
    "    # Sum votes by group and party\n",
    "    grouped = df.groupby([group_col, 'party_name'])[['2021_num_votes', '2025_num_votes']].sum().reset_index()\n",
    "\n",
    "    # Compute total votes per group (excluding Rejected already)\n",
    "    totals = grouped.groupby(group_col)[['2021_num_votes', '2025_num_votes']].sum().rename(columns={\n",
    "        '2021_num_votes': '2021_total',\n",
    "        '2025_num_votes': '2025_total'\n",
    "    }).reset_index()\n",
    "\n",
    "    # Merge totals back\n",
    "    merged = grouped.merge(totals, on=group_col)\n",
    "\n",
    "    # Calculate percentages\n",
    "    merged['2021_pct_vote'] = (merged['2021_num_votes'] / merged['2021_total']) * 100\n",
    "    merged['2025_pct_vote'] = (merged['2025_num_votes'] / merged['2025_total']) * 100\n",
    "    merged['pct_vote_change'] = merged['2025_pct_vote'] - merged['2021_pct_vote']\n",
    "\n",
    "    # Final formatting\n",
    "    final = merged[[group_col, 'party_name', '2021_pct_vote', '2025_pct_vote', 'pct_vote_change']]\n",
    "    final.loc[:, ['2021_pct_vote', '2025_pct_vote', 'pct_vote_change']] = final[\n",
    "        ['2021_pct_vote', '2025_pct_vote', 'pct_vote_change']\n",
    "    ].round(4)\n",
    "\n",
    "    # Save to CSV\n",
    "    final.to_csv(output_path, index=False)\n",
    "    return final\n",
    "\n",
    "# Compute for both CSDs and regions\n",
    "csd_final = compute_vote_shares(df.copy(), 'CSD', '../data/results/votes/csd_results.csv')\n",
    "region_final = compute_vote_shares(df.copy(), 'region', '../data/results/votes/region_results.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to convert a dataframe to the nested dictionary format\n",
    "def df_to_nested_dict(df, group_col):\n",
    "    output = {}\n",
    "    for name, group in df.groupby(group_col):\n",
    "        output[name] = {\n",
    "            '2021_pct_vote': {},\n",
    "            '2025_pct_vote': {},\n",
    "            'pct_vote_change': {}\n",
    "        }\n",
    "        for _, row in group.iterrows():\n",
    "            tag = PARTY_TAGS_MAP.get(row['party_name'], row['party_name'])\n",
    "            output[name]['2021_pct_vote'][tag] = row['2021_pct_vote']\n",
    "            output[name]['2025_pct_vote'][tag] = row['2025_pct_vote']\n",
    "            output[name]['pct_vote_change'][tag] = row['pct_vote_change']\n",
    "    return output\n",
    "\n",
    "# Generate nested dictionaries\n",
    "csd_results_dict = df_to_nested_dict(csd_final, 'CSD')\n",
    "region_results_dict = df_to_nested_dict(region_final, 'region')\n",
    "\n",
    "# Save CSD results to JSON\n",
    "with open('../data/results/votes/csd_results.json', 'w') as f:\n",
    "    json.dump(csd_results_dict, f, indent=4)\n",
    "\n",
    "# Save region results to JSON\n",
    "with open('../data/results/votes/region_results.json', 'w') as f:\n",
    "    json.dump(region_results_dict, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the number of seats that each party wins in each CSD/region category, as well as the number of flips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge riding metadata into the results to get CSD and region info\n",
    "df_results = df_results.merge(df_ridings[['FED_NUM', 'CSD', 'region']], on='FED_NUM', how='left')\n",
    "\n",
    "# Group by FED_NUM and party to find the total votes per party per riding\n",
    "riding_winners = df_results.groupby(['FED_NUM', 'FED_name', 'party_name'])[\n",
    "    ['2021_num_votes', '2025_num_votes']\n",
    "].sum().reset_index()\n",
    "\n",
    "# Get 2021 winners\n",
    "winners_2021 = riding_winners.loc[riding_winners.groupby('FED_NUM')['2021_num_votes'].idxmax()]\n",
    "winners_2021 = winners_2021[['FED_NUM', 'party_name']].rename(columns={'party_name': 'prevParty'})\n",
    "\n",
    "# Get 2025 winners\n",
    "winners_2025 = riding_winners.loc[riding_winners.groupby('FED_NUM')['2025_num_votes'].idxmax()]\n",
    "winners_2025 = winners_2025[['FED_NUM', 'FED_name', 'party_name']].rename(columns={'party_name': 'curParty'})\n",
    "\n",
    "# Merge winners and add riding metadata\n",
    "df_flips = pd.merge(winners_2021, winners_2025, on='FED_NUM')\n",
    "df_flips = pd.merge(df_flips, df_ridings[['FED_NUM', 'CSD', 'region']], on='FED_NUM', how='left')\n",
    "\n",
    "# Determine if flipped\n",
    "df_flips['isFlipped'] = df_flips['prevParty'] != df_flips['curParty']\n",
    "\n",
    "# Map party names to tags\n",
    "df_flips['prevParty'] = df_flips['prevParty'].map(PARTY_TAGS_MAP)\n",
    "df_flips['curParty'] = df_flips['curParty'].map(PARTY_TAGS_MAP)\n",
    "\n",
    "# Define suburb logic\n",
    "SUBURB_CORES = {\n",
    "    'Greater Montreal': 'Island of Montreal',\n",
    "    'Greater Toronto Area': 'Toronto',\n",
    "    'Metro Vancouver': 'Vancouver',\n",
    "}\n",
    "\n",
    "def is_suburb(row):\n",
    "    core_city = SUBURB_CORES.get(row['region'])\n",
    "    return row['region'] in SUBURB_CORES and row['CSD'] != core_city\n",
    "\n",
    "df_flips['isSuburb'] = df_flips.apply(is_suburb, axis=1)\n",
    "\n",
    "# Final ordering of columns\n",
    "df_flips = df_flips[['FED_NUM', 'FED_name', 'CSD', 'region', 'isSuburb', 'prevParty', 'curParty', 'isFlipped']]\n",
    "\n",
    "df_flips.to_csv('../data/results/seats/all_seat_flips.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Ensure all column names are strings and appropriate types\n",
    "df_flips = df_flips.astype({\n",
    "    'FED_NUM': int,\n",
    "    'FED_name': str,\n",
    "    'CSD': str,\n",
    "    'region': str,\n",
    "    'prevParty': str,\n",
    "    'curParty': str,\n",
    "    'isFlipped': bool,\n",
    "    'isSuburb': bool\n",
    "})\n",
    "\n",
    "# Convert DataFrame to list of dicts\n",
    "riding_dicts = df_flips.to_dict(orient='records')\n",
    "\n",
    "# Group by region\n",
    "region_dict = {}\n",
    "for row in riding_dicts:\n",
    "    region = row['region']\n",
    "    region_dict.setdefault(region, []).append(row)\n",
    "region_dict.pop('nan', None)\n",
    "\n",
    "# Add suburb-only keys to region_dict\n",
    "SUBURB_REGIONS = ['Greater Montreal', 'Greater Toronto Area', 'Metro Vancouver']\n",
    "for base_region in SUBURB_REGIONS:\n",
    "    suburb_key = f\"{base_region} (suburbs only)\"\n",
    "    region_dict[suburb_key] = [row for row in riding_dicts if row['region'] == base_region and row['isSuburb']]\n",
    "\n",
    "# Group by CSD\n",
    "csd_dict = {}\n",
    "for row in riding_dicts:\n",
    "    csd = row['CSD']\n",
    "    csd_dict.setdefault(csd, []).append(row)\n",
    "csd_dict.pop('nan', None)\n",
    "\n",
    "# Add suburb-only keys to csd_dict using same suburb filter\n",
    "for base_region in SUBURB_REGIONS:\n",
    "    suburb_key = f\"{base_region} (suburbs only)\"\n",
    "    csd_dict[suburb_key] = [row for row in riding_dicts if row['region'] == base_region and row['isSuburb']]\n",
    "\n",
    "# Save to JSON\n",
    "with open('../data/results/seats/region_seat_flips.json', 'w') as f:\n",
    "    json.dump(region_dict, f, indent=4)\n",
    "\n",
    "with open('../data/results/seats/csd_seat_flips.json', 'w') as f:\n",
    "    json.dump(csd_dict, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
